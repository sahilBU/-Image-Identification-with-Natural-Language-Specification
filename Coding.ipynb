{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Details Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Preparing Data folders\n",
    "\n",
    "Note : May get a warning in the jupter notebook but you can ignore the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ars/AI/project/Data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-eabb57b16b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mimg_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#Normalizing data according to image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "#Prepare dataset for one folder\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "os.chdir('/Users/ars/AI/project')\n",
    "os.chdir(os.path.join(os.getcwd(),'Data'))\n",
    "print(os.getcwd())\n",
    "\n",
    "fl = os.listdir(os.getcwd())\n",
    "#fl.remove('.DS_Store')\n",
    "\n",
    "for dirName in fl:\n",
    "    path='/Users/ars/AI/project/Data/'+dirName+'/img/'\n",
    "    list1=os.listdir(path)\n",
    "    list1.sort()\n",
    "    for img in list1:\n",
    "        dst= path+dirName[0:len(dirName)-2]+img[-10:]\n",
    "        src= path+img\n",
    "        #print(src,dst)\n",
    "        os.rename(src,dst)\n",
    "\n",
    "df =pd.DataFrame(columns = ['label','x','y','width','height','img_name'])\n",
    "\n",
    "#Combining dataset\n",
    "for i in range(len(fl)):\n",
    "    #Label\n",
    "    label = fl[i]\n",
    "    \n",
    "    #Bounding Box\n",
    "    bbox = pd.read_csv(os.getcwd()+'/'+label+'/groundtruth.txt', sep=\",\", header=None)\n",
    "    bbox.columns = ['x','y','width','height']\n",
    "    \n",
    "    #Images\n",
    "    img = os.listdir(os.path.join(os.getcwd(),label,'img'))\n",
    "    img.sort()\n",
    "    \n",
    "    #Datset for the folder\n",
    "    train = pd.DataFrame(columns = ['label','x','y','width','height'])\n",
    "    train[\"label\"] = pd.Series([label[0:len(fl[i])-2]]*bbox.shape[0])\n",
    "    \n",
    "    train.iloc[:,1:5] = bbox[:]\n",
    "    #print(train.shape)\n",
    "    img_folder = str(os.path.join(os.getcwd(),label,'img')) + '/'\n",
    "    \n",
    "    train[\"img_name\"] = img\n",
    "    \n",
    "    #Normalizing data according to image size\n",
    "    im = Image.open(os.path.join(os.getcwd(),label,'img',img[0]))\n",
    "    width, height = im.size\n",
    "    \n",
    "    train['x'] = train['x']/width\n",
    "    train['y'] = train['y']/height\n",
    "    train['width'] = train['width']/width\n",
    "    train['height'] = train['width']/height\n",
    "\n",
    "    #Combining dataset\n",
    "    df = df.append(train)\n",
    "    \n",
    "fl.sort()\n",
    "\n",
    "label_names = {}\n",
    "for i in range(len(fl)):\n",
    "    label_names[str(fl[i][0:len(fl[i])-2])] = i\n",
    "\n",
    "print(label_names)\n",
    "df_new = df[:]\n",
    "df_new[\"label\"].replace(label_names, inplace =True)\n",
    "\n",
    "print(df_new.iloc[0][5].split('.')[0]+'.txt')\n",
    "\n",
    "txt_dir='/Users/ars/AI/project/text/'\n",
    "\n",
    "os.chdir(txt_dir)\n",
    "\n",
    "for j in range(len(df_new)):\n",
    "    with open (df_new.iloc[j][5].split('.')[0]+'.txt','w') as f:\n",
    "        for i in range(0,5):\n",
    "            f.write(\"%s\" % df.iloc[j][i]+\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split Training and testing data\n",
    "\n",
    "This will split the images in the path into snowman_test.txt and snowman_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done splitting data into test and train\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "imagesFolder='/Users/ars/AI/project/JPEGImages'\n",
    "def split_data_set(image_dir):\n",
    "\n",
    "    f_val = open(\"snowman_test.txt\", 'w')\n",
    "    f_train = open(\"snowman_train.txt\", 'w')\n",
    "    \n",
    "    path, dirs, files = next(os.walk(image_dir))\n",
    "    data_size = len(files)\n",
    "\n",
    "    ind = 0\n",
    "    data_test_size = int(0.1 * data_size)\n",
    "    test_array = random.sample(range(data_size), k=data_test_size)\n",
    "    \n",
    "    for f in os.listdir(image_dir):\n",
    "        if(f.split(\".\")[1] == \"jpg\"):\n",
    "            ind += 1\n",
    "            \n",
    "            if ind in test_array:\n",
    "                f_val.write(image_dir+'/'+f+'\\n')\n",
    "            else:\n",
    "                f_train.write(image_dir+'/'+f+'\\n')\n",
    "\n",
    "\n",
    "split_data_set(imagesFolder)\n",
    "print('Done splitting data into test and train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Getting all the annotations of all images in the data set this includes all the annotations for 20 videos in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da  :  white airplane landing on ground\n"
     ]
    }
   ],
   "source": [
    "import glob2\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(r'/Users/ars/AI/project/Data')\n",
    "# txt_files_only_subdirs = path.glob('*/nlp.txt')\n",
    "txt_files_all_recursively = path.rglob('nlp*.txt') # including the current dir\n",
    "#category = txt_files_all_recursively.split('/')\n",
    "#print(category)\n",
    "\n",
    "for file in txt_files_all_recursively:\n",
    "    category = str(file).split('/')\n",
    "    #print(category[5])\n",
    "    contents = open(str(file),\"r\") \n",
    "    print(category[5][:-2],\" : \",contents.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Below is the code is plot training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data and plotting training loss graph...\n",
      "Done! Plot saved as training_loss_plot.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lines = []\n",
    "logFilePath='/Users/ars/AI/project/training.log'\n",
    "for line in open(logFilePath):\n",
    "    if \"avg\" in line:\n",
    "        lines.append(line)\n",
    "\n",
    "iterations = []\n",
    "avg_loss = []\n",
    "\n",
    "print('Retrieving data and plotting training loss graph...')\n",
    "for i in range(len(lines)):\n",
    "    lineParts = lines[i].split(',')\n",
    "    iterations.append(int(lineParts[0].split(':')[0]))\n",
    "    avg_loss.append(float(lineParts[1].split()[0]))\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(0, len(lines)):\n",
    "    plt.plot(iterations[i:i+2], avg_loss[i:i+2], 'r.-')\n",
    "\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Avg Loss')\n",
    "fig.savefig('training_loss_plot.png', dpi=1000)\n",
    "# display(fig)\n",
    "\n",
    "print('Done! Plot saved as training_loss_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Below is the code for Glove CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ars/AI/ai/rnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5f85cbaf5ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/ars/AI/ai/rnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/ars/AI/ai/rnn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'annotations.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ars/AI/ai/rnn'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr 11 01:06:01 2019\n",
    "\"\"\"\n",
    "from keras.models import load_model\n",
    "import os\n",
    "os.getcwd()\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "os.chdir('/Users/ars/AI/ai/rnn')\n",
    "\n",
    "annotation = open(os.path.join('/Users/ars/AI/ai/rnn','annotations.txt'))\n",
    "\n",
    "df = pd.DataFrame(columns = ['text','labels'])\n",
    "\n",
    "row_cnt = 0\n",
    "\n",
    "#Create dictionary for labels\n",
    "for i in annotation.readlines():\n",
    "\n",
    "    x = i.split('.txt  :  ')\n",
    "    \n",
    "    label_text = x[0].split('/')\n",
    "    label_text = label_text[len(label_text)-3]\n",
    "    \n",
    "    text = x[1]\n",
    "    text = text[0:len(text)-1]\n",
    "    \n",
    "    df = df.append({'labels':label_text,'text':text}, ignore_index = True)\n",
    "    \n",
    "    row_cnt += 1\n",
    "\n",
    "#Creating dictionary\n",
    "label_set = list(set(df['labels']))\n",
    "label_set.sort()\n",
    "\n",
    "labels_index = {}\n",
    "\n",
    "for i in range(len(label_set)):\n",
    "    labels_index[label_set[i]] = i\n",
    "\n",
    "#List of labels and texts\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "i = 0\n",
    "for i in range(df.shape[0]):\n",
    "    texts.append(df.text.iloc[i])\n",
    "    labels.append(labels_index[df.labels.iloc[i]])\n",
    "\n",
    "#Defining MAX_NB_length\n",
    "#Defining MAX_SEQUENCE_LENGTH\n",
    "unique_words = []\n",
    "max_l = 0\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    split_words = texts[i].split(' ')\n",
    "    unique_words.extend(split_words)\n",
    "    if(len(split_words) > max_l):\n",
    "        max_l = len(split_words)\n",
    "\n",
    "\n",
    "MAX_NB_WORDS = len(set(unique_words))\n",
    "MAX_SEQUENCE_LENGTH = max_l\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "VALIDATION_SPLIT = 0.25\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "## Preparing embedding layer\n",
    "\n",
    "embeddings_index = {}\n",
    "GLOVE_DIR = os.path.join(os.getcwd(),'glove.6B')\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "## Preparing embedding matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "## Loading embedding matrix into embedding layer\n",
    "from keras.layers import Embedding\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "        \n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "## Training Conv Net\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(128, 2, activation='relu')(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Conv1D(128, 2, activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# happy learning!\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=20, batch_size=5)\n",
    "\n",
    "#New prediction\n",
    "new_text ='swimming in the water'\n",
    "new_text = new_text.split(' ')\n",
    "    \n",
    "sequences = tokenizer.texts_to_sequences(new_text)\n",
    "\n",
    "text_input = []\n",
    "for i in range(len(sequences)):\n",
    "    text_input.extend(sequences[i])\n",
    "\n",
    "text_input = [text_input]\n",
    "data = pad_sequences(text_input, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(data)\n",
    "\n",
    "np.argmax(model.predict(data))\n",
    "\n",
    "model.save('glove_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Below is the code for object detection once the training is done \n",
    "\n",
    "Note: This code is not capable of running in jupyter notebook. I included instructions on how to run it below\n",
    "\n",
    "Command format : python3 object_detection_yolo.py --image=/home/santoshganti/learnopencv/YOLOv3-Training-Snowman-Detector/snowman_test_subset.txt\n",
    "\n",
    "--image will take argument for the path to test file i.e., snowman_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is written at BigVision LLC. It is based on the OpenCV project. It is subject to the license terms in the LICENSE file found in this distribution and at http://opencv.org/license.html\n",
    "\n",
    "# Usage example:  python3 object_detection_yolo.py --video=run.mp4\n",
    "#                 python3 object_detection_yolo.py --image=bird.jpg\n",
    "\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import pickle\n",
    "from keras.models import load_model \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize the parameters\n",
    "#confThreshold = 0.5  #Confidence threshold\n",
    "#nmsThreshold = 0.4  # Non-maximum suppression threshold\n",
    "\n",
    "inpWidth = 416  #608     #Width of network's input image\n",
    "inpHeight = 416 #608     #Height of network's input image\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Object Detection using YOLO in OPENCV')\n",
    "parser.add_argument('--image', help='Path to image file.')\n",
    "parser.add_argument('--video', help='Path to video file.')\n",
    "args = parser.parse_args()\n",
    "        \n",
    "# Load names of classes\n",
    "classesFile = \"classes.names\";\n",
    "\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "\n",
    "modelConfiguration = \"/Users/ars/AI/learnopencv/YOLOv3-Training-Snowman-Detector/darknet-yolov3.cfg\";\n",
    "modelWeights = \"/Users/ars/AI/learnopencv/YOLOv3-Training-Snowman-Detector/weights/darknet-yolov3_final.weights\";\n",
    "\n",
    "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "# Get the names of the output layers\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "def draw_max(max_conf,my_det,my_classId,frame):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "     #print(\"my_det \", my_det)\n",
    "    if len(my_det) == 0:\n",
    "        return [0, 0, 0, 0, 0]\n",
    "    center_x = int(my_det[0] * frameWidth)\n",
    "    center_y = int(my_det[1] * frameHeight)\n",
    "    width = int(my_det[2] * frameWidth)\n",
    "    height = int(my_det[3] * frameHeight)\n",
    "    left = int(center_x - width / 2)\n",
    "    top = int(center_y - height / 2)\n",
    "    classIds.append(my_classId)\n",
    "    confidences.append(float(max_conf))\n",
    "    #boxes.append([left, top, width, height])\n",
    "    \n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    #indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    drawPred(classIds[0], confidences[0], left, top, left + width, top + height)\n",
    "    return[classIds[0], left, top, left + width, top + height]\n",
    "# Draw the predicted bounding box\n",
    "def drawPred(classId, conf, left, top, right, bottom):\n",
    "    # Draw a bounding box.\n",
    "    #    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 3)\n",
    "\n",
    "    label = '%.2f' % conf\n",
    "        \n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "\n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (0, 0, 255), cv.FILLED)\n",
    "    #cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine),    (255, 255, 255), cv.FILLED)\n",
    "    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 2)\n",
    "\n",
    "# Remove the bounding boxes with low confidence using non-maxima suppression\n",
    "def postprocess(frame, outs, object_class):\n",
    "    #print (\"outs :\", outs)\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    \n",
    "    boxes = []\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    max_conf = 0\n",
    "    my_det = []\n",
    "    for out in outs:\n",
    "        #print(\"out.shape : \", out.shape)\n",
    "        for detection in out:\n",
    "            #if detection[4]>0.001:\n",
    "            scores = detection[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            \n",
    "            #if scores[classId]>confThreshold:\n",
    "            confidence = scores[classId]\n",
    "            #print(classId)\n",
    "            #print(\"object class:\",object_class)\n",
    "            if (object_class==classId and confidence > max_conf):\n",
    "                #print(\"confidence \", confidence)\n",
    "                max_conf = confidence\n",
    "                my_det = detection \n",
    "    return [max_conf,my_det,object_class,frame]\n",
    "    \n",
    "\n",
    "# Process inputs\n",
    "winName = 'Deep learning object detection in OpenCV'\n",
    "cv.namedWindow(winName, cv.WINDOW_NORMAL)\n",
    "outputFile = \"yolo_out_py.avi\"\n",
    "\n",
    "txtFile = open(args.image,'r')\n",
    "txt = txtFile.readlines()\n",
    "\n",
    "label_line = txt.pop(0)\n",
    "\n",
    "new_text = label_line.split(' ')\n",
    "\n",
    "with open('/Users/ars/AI/ai/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(new_text)\n",
    "text_input = []\n",
    "for i in range(len(sequences)):\n",
    "    text_input.extend(sequences[i])\n",
    "\n",
    "text_input = [text_input]\n",
    "MAX_SEQUENCE_LENGTH=16\n",
    "data = pad_sequences(text_input, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "model = load_model('/Users/ars/AI/ai/glovecnn.h5')\n",
    "object_class = np.argmax(model.predict(data))\n",
    "print(\"object\",object_class)\n",
    "path=args.image[:-4]\n",
    "list_main=[]\n",
    "count=0\n",
    "max_confidance=0\n",
    "max_conf_list=[]\n",
    "out_dir=''\n",
    "counter=0\n",
    "for img in txt:\n",
    "    counter=counter+1\n",
    "    img=img[:-1]\n",
    "    image_link = str(img)\n",
    "    image_name=image_link.split(\"/\")[-1][:-4]\n",
    "    \n",
    "    if (args.image):\n",
    "        # Open the image file\n",
    "        if not os.path.isfile(image_link):\n",
    "            print(\"Input image file \", image_link, \" doesn't exist\")\n",
    "            sys.exit(1)\n",
    "        cap = cv.VideoCapture(image_link)\n",
    "        outputFile = path+\"/\"+image_name+'_yolo_out_py.jpg'\n",
    "    elif (args.video):\n",
    "        # Open the video file\n",
    "        if not os.path.isfile(args.video):\n",
    "            print(\"Input video file \", args.video, \" doesn't exist\")\n",
    "            sys.exit(1)\n",
    "        cap = cv.VideoCapture(args.video)\n",
    "        outputFile = args.video[:-4]+'_yolo_out_py.avi'\n",
    "    else:\n",
    "        # Webcam input\n",
    "        cap = cv.VideoCapture(0)\n",
    "\n",
    "    # Get the video writer initialized to save the output video\n",
    "    if (not args.image):\n",
    "        vid_writer = cv.VideoWriter(outputFile, cv.VideoWriter_fourcc('M','J','P','G'), 30, (round(cap.get(cv.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "    while cv.waitKey(1) < 0:\n",
    "\n",
    "        # get frame from the video\n",
    "        hasFrame, frame = cap.read()\n",
    "\n",
    "        # Stop the program if reached end of video\n",
    "        if not hasFrame:\n",
    "            #print(\"Done processing !!!\")\n",
    "            #print(\"Output file is stored as \", outputFile)\n",
    "            cv.waitKey(3000)\n",
    "            break\n",
    "\n",
    "        # Create a 4D blob from a frame.\n",
    "        blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "\n",
    "        # Sets the input to the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Runs the forward pass to get output of the output layers\n",
    "        outs = net.forward(getOutputsNames(net))\n",
    "\n",
    "        # Remove the bounding boxes with low confidence\n",
    "        \n",
    "        list1 = postprocess(frame, outs,object_class)\n",
    "        if(list1[0]>max_confidance):\n",
    "            max_conf_list=list1\n",
    "            out_dir=outputFile\n",
    "            \n",
    "        print(\"length\",out_dir)\n",
    "        if(counter==len(txt)):\n",
    "            if(len(max_conf_list)!=0):\n",
    "                print(\"in write \",out_dir)\n",
    "                draw_max(max_conf_list[0],max_conf_list[1],max_conf_list[2],max_conf_list[3])\n",
    "                t, _ = net.getPerfProfile()\n",
    "                label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
    "                cv.imwrite(out_dir, max_conf_list[3].astype(np.uint8))\n",
    "                cv.imshow(winName, max_conf_list[3])\n",
    "            else:\n",
    "                print(\"No Image with given discription\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Below is the code for getting iou scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('/Users/ars/AI/project/out.csv')\n",
    "\n",
    "#print(df.columns.values)\n",
    "\n",
    "df.drop([\"Unnamed: 0\"],axis=1,inplace=True)\n",
    "df.columns = ['image_path','class_label','left','up','right','down']\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(columns = ['image_path','class_label','left','up','right','down'])\n",
    "ap = []\n",
    "\n",
    "def find_match(contents, x):\n",
    "    \n",
    "    obj = contents.split(' ')\n",
    "    \n",
    "    obj_class = str(obj[0])\n",
    "    obj_left = float(obj[1]) / 416.0\n",
    "    obj_up = float(obj[2]) / 416.0\n",
    "    obj_right = float(obj_up) + float(obj[3]) / 416.0\n",
    "    obj_down = obj_left + float(obj[4]) / 416.0\n",
    "    \n",
    "    x_min = max(x[2], obj_left)\n",
    "    x_max = min(x[2]+x[4], obj_right)\n",
    "    y_min = max(x[3], obj_up)\n",
    "    y_max = min(x[3]+x[5], obj_down)\n",
    "    \n",
    "    area = max(( x_max - x_min ) * ( y_max - y_min ) ,0)\n",
    "    actual = x[4] * x[5]\n",
    "    \n",
    "    if(actual ==0):\n",
    "        return 0\n",
    "    score = area/actual\n",
    "    \n",
    "\n",
    "    match_class = ( int(x[1]) ==int( obj_class) )*1\n",
    "\n",
    "    return(score*match_class)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    x = df.iloc[i]\n",
    "    file_name = x[0].split(\"/\")[-1][:-4]\n",
    "    file_name = str(file_name) + '.txt'\n",
    "    label_dir = '/Users/ars/AI/project/labels'\n",
    "    \n",
    "    f = open(os.path.join(label_dir, file_name))\n",
    "    contents = f.read()\n",
    "    \n",
    "    area = find_match(contents, x)\n",
    "    \n",
    "    ap.append(area)\n",
    "\n",
    "    \n",
    "ser = pd.Series(ap)\n",
    "print(ser.mean())\n",
    "ser.to_csv('iou_scores.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
